import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
import os
import glob
import cv2
import matplotlib.pyplot as plt
from keras.models import Sequential
from keras.layers import Dense, BatchNormalization, LeakyReLU, Flatten
from keras.layers import Conv2D, AveragePooling2D
from keras.optimizers import Adam
from keras.callbacks.callbacks import EarlyStopping

## Define File Locations (Images, Figure of Merit, and CNN Model Save)
img_path = 'C:/Users/dh361/Documents/ysplitter/halfimages/*.png'
fom_path = 'C:/Users/dh361/Desktop/FigureofMeritV2lasthalf_catwavelength.csv'
save_dir = 'C:/Users/dh361/Documents/TrainingDataResults/halfimagesfomcatwavelength.h5'

## Load Images (CNN Input)
def loadImages(path):
    loadedImages = []
    filesname = glob.glob(path)
    filesname.sort()
    for imgdata in filesname:
        if os.path.isfile(os.path.splitext(os.path.join(path, imgdata))[0] + ".png"):
            img_array = cv2.imread(os.path.join(path, imgdata))
            img_array = np.float32(img_array)
            img_size = 128
            new_array = cv2.resize(img_array, (img_size, img_size))
            gray = cv2.cvtColor(new_array, cv2.COLOR_BGR2GRAY)       
            loadedImages.append(gray)
    return loadedImages

imgs = loadImages(img_path)
CNN_input = np.array(imgs).reshape(len(imgs),128,128,1)

## Load Figure of Merit from Excel (CNN Output)
CNN_output = np.array(np.float32(pd.read_csv(fom_path, header = 0, usecols = ['FOM','1300', '1400', '1500', '1600', '1700', '1800'])))

# Split Data into Train and Test Sets
CNN_input_train, CNN_input_test, CNN_output_train, CNN_output_test = train_test_split(CNN_input, CNN_output, test_size = 0.1, random_state = 42)
print('data size after spliting')
print('CNN_input_train size: {}'.format(np.shape(CNN_input_train)))
print('CNN_input_test size: {}'.format(np.shape(CNN_input_test)))
print('CNN_output_train size: {}'.format(np.shape(CNN_output_train)))
print('CNN_output_test size: {}'.format(np.shape(CNN_output_test)))

# Define CNN Architecture, this took a lot of trial and error
model = Sequential()
model.add(Conv2D(16, (3,3), padding = 'same', input_shape = (128,128,1)))
model.add(BatchNormalization())
model.add(LeakyReLU(0.2))
model.add(AveragePooling2D(pool_size = (2,2), strides = 2))
model.add(Conv2D(32, (3,3), padding = 'same'))
model.add(BatchNormalization())
model.add(LeakyReLU(0.2))
model.add(AveragePooling2D(pool_size = (2,2), strides = 2))
model.add(Conv2D(64, (3,3), padding = 'same'))
model.add(BatchNormalization())
model.add(LeakyReLU(0.2))
model.add(AveragePooling2D(pool_size = (2,2), strides = 2))
model.add(Conv2D(128, (3,3), padding = 'same'))
model.add(BatchNormalization())
model.add(LeakyReLU(0.2))
model.add(AveragePooling2D(pool_size = (2,2), strides = 2))
model.add(Conv2D(256, (3,3), padding = 'same'))
model.add(BatchNormalization())
model.add(LeakyReLU(0.2))
model.add(AveragePooling2D(pool_size = (2,2), strides = 2))
model.add(Flatten())
model.add(Dense(7)) 
#Dense is equal to 7, because I am trying to output a figure of merit value and 6 values that determine the wavelength at which it is being optimized


cnnopt = Adam()
model.compile(loss = 'mean_squared_error', optimizer = cnnopt, metrics = ['accuracy'])
print(model.summary())        

# Train and Save CNN
epochs = 1000
batch_size = 16
validation_data = (CNN_input_test, CNN_output_test)
#early stop criteria exists in case you don't need 1000 epochs for the losses to converge
#es = EarlyStopping(monitor='val_loss', min_delta=0, patience=25, verbose=0, mode='auto', restore_best_weights=True)
history = model.fit(CNN_input_train, CNN_output_train, batch_size = batch_size, epochs = epochs, validation_data = validation_data)
score = model.evaluate(CNN_input_test, CNN_output_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])
print(model.summary())
model.save(save_dir)

# Plot metrics
fig, ax1 = plt.subplots()
ax1.plot(history.history['loss'], color = 'b', label = 'Training Loss')
ax1.plot(history.history['val_loss'], color = 'r', label = 'Validation Loss')
ax1.set_ylim([0, 0.01])
ax1.set_ylabel('Loss')
ax1.set_xlabel('Epochs')
plt.legend(loc = 'upper right')
plt.show()


